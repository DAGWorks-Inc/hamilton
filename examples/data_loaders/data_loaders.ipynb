{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data_csv.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from hamilton.function_modifiers import load_from, value\n",
    "\n",
    "\n",
    "@load_from.csv(path=value(\"test_data/marketing_spend.csv\"))\n",
    "def spend(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Takes in the dataframe and then generates a date index column to it,\n",
    "    where each row is a day starting from 2020-01-01\"\"\"\n",
    "    data[\"date\"] = pd.date_range(start=\"2020-01-01\", periods=len(data), freq=\"D\")\n",
    "    return data\n",
    "\n",
    "\n",
    "@load_from.csv(path=value(\"test_data/churn.csv\"))\n",
    "def churn(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Takes in the dataframe and then generates a date index column to it,\n",
    "    where each row is a day starting from 2020-01-01\n",
    "    \"\"\"\n",
    "    data[\"date\"] = pd.date_range(start=\"2020-01-01\", periods=len(data), freq=\"D\")\n",
    "    return data\n",
    "\n",
    "\n",
    "@load_from.csv(path=value(\"test_data/signups.csv\"))\n",
    "def signups(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Takes in the dataframe and then generates a date index column to it,\n",
    "    where each row is a day starting from 2020-01-01\n",
    "    \"\"\"\n",
    "    data[\"date\"] = pd.date_range(start=\"2020-01-01\", periods=len(data), freq=\"D\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data_duckdb.py\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def connection(db_path: str) -> duckdb.DuckDBPyConnection:\n",
    "    return duckdb.connect(database=db_path)\n",
    "\n",
    "\n",
    "def spend(connection: duckdb.DuckDBPyConnection) -> pd.DataFrame:\n",
    "    return connection.execute(\"select * from marketing_spend\").fetchdf()\n",
    "\n",
    "\n",
    "def churn(connection: duckdb.DuckDBPyConnection) -> pd.DataFrame:\n",
    "    return connection.execute(\"select * from churn\").fetchdf()\n",
    "\n",
    "\n",
    "def signups(connection: duckdb.DuckDBPyConnection) -> pd.DataFrame:\n",
    "    return connection.execute(\"select * from signups\").fetchdf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data_mock.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def spend() -> pd.DataFrame:\n",
    "    data = np.array(\n",
    "        [\n",
    "            (\n",
    "                \"2022-08-03T00:00:00.000000000\",\n",
    "                104052.98074001,\n",
    "                115300.21226012,\n",
    "                69384.46649019,\n",
    "                49474.45580366,\n",
    "                12851.6540992,\n",
    "                1498.5114764,\n",
    "                \"2022-08-03T00:00:00.000000000\",\n",
    "            ),\n",
    "            (\n",
    "                \"2022-08-04T00:00:00.000000000\",\n",
    "                103234.15793884,\n",
    "                115326.0151612,\n",
    "                71113.31018247,\n",
    "                52513.19734904,\n",
    "                12344.42778548,\n",
    "                1033.79398268,\n",
    "                \"2022-08-04T00:00:00.000000000\",\n",
    "            ),\n",
    "            (\n",
    "                \"2022-08-05T00:00:00.000000000\",\n",
    "                101816.40188563,\n",
    "                115194.04661767,\n",
    "                71367.20874633,\n",
    "                51795.51413309,\n",
    "                11536.41253561,\n",
    "                2101.46146166,\n",
    "                \"2022-08-05T00:00:00.000000000\",\n",
    "            ),\n",
    "            (\n",
    "                \"2022-08-06T00:00:00.000000000\",\n",
    "                102263.53043232,\n",
    "                115601.2888751,\n",
    "                71474.76280964,\n",
    "                52861.22158421,\n",
    "                11652.28867968,\n",
    "                1046.83170946,\n",
    "                \"2022-08-06T00:00:00.000000000\",\n",
    "            ),\n",
    "            (\n",
    "                \"2022-08-07T00:00:00.000000000\",\n",
    "                103271.09660695,\n",
    "                115306.96341012,\n",
    "                71888.99025677,\n",
    "                50742.70043588,\n",
    "                11160.23631976,\n",
    "                2521.31311947,\n",
    "                \"2022-08-07T00:00:00.000000000\",\n",
    "            ),\n",
    "            (\n",
    "                \"2022-08-08T00:00:00.000000000\",\n",
    "                100775.86701231,\n",
    "                116634.88666304,\n",
    "                71603.50462531,\n",
    "                52361.08798097,\n",
    "                12869.33161266,\n",
    "                3269.57027156,\n",
    "                \"2022-08-08T00:00:00.000000000\",\n",
    "            ),\n",
    "            (\n",
    "                \"2022-08-09T00:00:00.000000000\",\n",
    "                101527.74726883,\n",
    "                114868.8422755,\n",
    "                70260.81680881,\n",
    "                49647.9754876,\n",
    "                13187.07115589,\n",
    "                2134.71274923,\n",
    "                \"2022-08-09T00:00:00.000000000\",\n",
    "            ),\n",
    "            (\n",
    "                \"2022-08-10T00:00:00.000000000\",\n",
    "                101150.73295175,\n",
    "                114941.32547639,\n",
    "                68802.02668922,\n",
    "                49590.55466274,\n",
    "                13129.31334755,\n",
    "                3328.0293293,\n",
    "                \"2022-08-10T00:00:00.000000000\",\n",
    "            ),\n",
    "            (\n",
    "                \"2022-08-11T00:00:00.000000000\",\n",
    "                100317.64365959,\n",
    "                115682.20050942,\n",
    "                67735.95105252,\n",
    "                50621.23723767,\n",
    "                14019.11780391,\n",
    "                2360.4382216,\n",
    "                \"2022-08-11T00:00:00.000000000\",\n",
    "            ),\n",
    "            (\n",
    "                \"2022-08-12T00:00:00.000000000\",\n",
    "                102024.067597,\n",
    "                116770.81592363,\n",
    "                66244.22984364,\n",
    "                49503.73825509,\n",
    "                14533.2726457,\n",
    "                1868.18205207,\n",
    "                \"2022-08-12T00:00:00.000000000\",\n",
    "            ),\n",
    "        ],\n",
    "        dtype=[\n",
    "            (\"index\", \"<M8[ns]\"),\n",
    "            (\"facebook\", \"<f8\"),\n",
    "            (\"twitter\", \"<f8\"),\n",
    "            (\"tv\", \"<f8\"),\n",
    "            (\"youtube\", \"<f8\"),\n",
    "            (\"radio\", \"<f8\"),\n",
    "            (\"billboards\", \"<f8\"),\n",
    "            (\"date\", \"<M8[ns]\"),\n",
    "        ],\n",
    "    )\n",
    "    return pd.DataFrame.from_records(data)\n",
    "\n",
    "\n",
    "def churn() -> pd.DataFrame:\n",
    "    data = np.array(\n",
    "        [\n",
    "            (\"2022-08-03T00:00:00.000000000\", 160, 53, \"2022-08-03T00:00:00.000000000\"),\n",
    "            (\"2022-08-04T00:00:00.000000000\", 162, 54, \"2022-08-04T00:00:00.000000000\"),\n",
    "            (\"2022-08-05T00:00:00.000000000\", 162, 50, \"2022-08-05T00:00:00.000000000\"),\n",
    "            (\"2022-08-06T00:00:00.000000000\", 161, 53, \"2022-08-06T00:00:00.000000000\"),\n",
    "            (\"2022-08-07T00:00:00.000000000\", 160, 49, \"2022-08-07T00:00:00.000000000\"),\n",
    "            (\"2022-08-08T00:00:00.000000000\", 160, 52, \"2022-08-08T00:00:00.000000000\"),\n",
    "            (\"2022-08-09T00:00:00.000000000\", 161, 53, \"2022-08-09T00:00:00.000000000\"),\n",
    "            (\"2022-08-10T00:00:00.000000000\", 160, 57, \"2022-08-10T00:00:00.000000000\"),\n",
    "            (\"2022-08-11T00:00:00.000000000\", 156, 56, \"2022-08-11T00:00:00.000000000\"),\n",
    "            (\"2022-08-12T00:00:00.000000000\", 148, 58, \"2022-08-12T00:00:00.000000000\"),\n",
    "        ],\n",
    "        dtype=[(\"index\", \"<M8[ns]\"), (\"womens\", \"<i8\"), (\"mens\", \"<i8\"), (\"date\", \"<M8[ns]\")],\n",
    "    )\n",
    "    return pd.DataFrame.from_records(data)\n",
    "\n",
    "\n",
    "def signups() -> pd.DataFrame:\n",
    "    data = np.array(\n",
    "        [\n",
    "            (\"2022-08-03T00:00:00.000000000\", 2184, 429, \"2022-08-03T00:00:00.000000000\"),\n",
    "            (\"2022-08-04T00:00:00.000000000\", 2164, 461, \"2022-08-04T00:00:00.000000000\"),\n",
    "            (\"2022-08-05T00:00:00.000000000\", 2159, 454, \"2022-08-05T00:00:00.000000000\"),\n",
    "            (\"2022-08-06T00:00:00.000000000\", 2157, 449, \"2022-08-06T00:00:00.000000000\"),\n",
    "            (\"2022-08-07T00:00:00.000000000\", 2121, 478, \"2022-08-07T00:00:00.000000000\"),\n",
    "            (\"2022-08-08T00:00:00.000000000\", 2151, 517, \"2022-08-08T00:00:00.000000000\"),\n",
    "            (\"2022-08-09T00:00:00.000000000\", 2133, 541, \"2022-08-09T00:00:00.000000000\"),\n",
    "            (\"2022-08-10T00:00:00.000000000\", 2160, 565, \"2022-08-10T00:00:00.000000000\"),\n",
    "            (\"2022-08-11T00:00:00.000000000\", 2135, 609, \"2022-08-11T00:00:00.000000000\"),\n",
    "            (\"2022-08-12T00:00:00.000000000\", 2116, 633, \"2022-08-12T00:00:00.000000000\"),\n",
    "        ],\n",
    "        dtype=[(\"index\", \"<M8[ns]\"), (\"womens\", \"<i8\"), (\"mens\", \"<i8\"), (\"date\", \"<M8[ns]\")],\n",
    "    )\n",
    "    return pd.DataFrame.from_records(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_data.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from hamilton.function_modifiers import does, extract_columns, parameterize, source, value\n",
    "\n",
    "\n",
    "def _sum_series(**series):\n",
    "    return sum(series.values())\n",
    "\n",
    "\n",
    "@extract_columns(\n",
    "    \"facebook_spend\",\n",
    "    \"twitter_spend\",\n",
    "    \"tv_spend\",\n",
    "    \"youtube_spend\",\n",
    "    \"radio_spend\",\n",
    "    \"billboards_spend\",\n",
    "    \"womens_churn\",\n",
    "    \"mens_churn\",\n",
    "    \"womens_signups\",\n",
    "    \"mens_signups\",\n",
    ")\n",
    "def joined_data(spend: pd.DataFrame, signups: pd.DataFrame, churn: pd.DataFrame) -> pd.DataFrame:\n",
    "    spend = spend.set_index(\"date\").rename(columns=lambda col: col + \"_spend\")\n",
    "    churn = churn.set_index(\"date\").rename(columns=lambda col: col + \"_churn\")\n",
    "    signups = signups.set_index(\"date\").rename(columns=lambda col: col + \"_signups\")\n",
    "    return pd.concat([spend, churn, signups], axis=1)\n",
    "\n",
    "\n",
    "@does(_sum_series)\n",
    "def total_marketing_spend(\n",
    "    facebook_spend: pd.Series,\n",
    "    twitter_spend: pd.Series,\n",
    "    tv_spend: pd.Series,\n",
    "    youtube_spend: pd.Series,\n",
    "    radio_spend: pd.Series,\n",
    "    billboards_spend: pd.Series,\n",
    ") -> pd.Series:\n",
    "    pass\n",
    "\n",
    "\n",
    "@does(_sum_series)\n",
    "def total_signups(mens_signups: pd.Series, womens_signups: pd.Series) -> pd.Series:\n",
    "    pass\n",
    "\n",
    "\n",
    "@does(_sum_series)\n",
    "def total_churn(mens_churn: pd.Series, womens_churn: pd.Series) -> pd.Series:\n",
    "    pass\n",
    "\n",
    "\n",
    "def total_customers(total_signups: pd.Series, total_churn: pd.Series) -> pd.Series:\n",
    "    customer_deltas = total_signups + total_churn\n",
    "    return customer_deltas.cumsum()\n",
    "\n",
    "\n",
    "def acquisition_cost(total_marketing_spend: pd.Series, total_signups: pd.Series) -> pd.Series:\n",
    "    return total_marketing_spend / total_signups\n",
    "\n",
    "\n",
    "@parameterize(\n",
    "    twitter_spend_smoothed={\"lookback_days\": value(7), \"spend\": source(\"twitter_spend\")},\n",
    "    facebook_spend_smoothed={\"lookback_days\": value(7), \"spend\": source(\"facebook_spend\")},\n",
    "    radio_spend_smoothed={\"lookback_days\": value(21), \"spend\": source(\"radio_spend\")},\n",
    "    tv_spend_smoothed={\"lookback_days\": value(21), \"spend\": source(\"tv_spend\")},\n",
    "    billboards_spend_smoothed={\"lookback_days\": value(7), \"spend\": source(\"billboards_spend\")},\n",
    "    youtube_spend_smoothed={\"lookback_days\": value(7), \"spend\": source(\"twitter_spend\")},\n",
    ")\n",
    "def spend_smoothed(lookback_days: int, spend: pd.Series) -> pd.Series:\n",
    "    \"\"\"{spend} smoothed by {lookback_days}. Might want to smooth different ad spends differently,\n",
    "    figuring that it takes different amounts of time to get to the customer. A cheap hack at determining\n",
    "    auto-correlation of a series -- this should be a parameter in a model,\n",
    "    but this is to demonstrate the framework\n",
    "\n",
    "    :param lookback_days: Days to smooth over\n",
    "    :param spend: Spend source\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return spend.rolling(window=lookback_days).mean().fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.py\n",
    "\n",
    "import click\n",
    "import load_data_csv\n",
    "import load_data_duckdb\n",
    "import load_data_mock\n",
    "import prep_data\n",
    "\n",
    "import hamilton.driver\n",
    "\n",
    "\n",
    "# @click.group()\n",
    "# def main():\n",
    "#     pass\n",
    "\n",
    "\n",
    "VARS = [\n",
    "    \"total_signups\",\n",
    "    \"total_churn\",\n",
    "    \"total_marketing_spend\",\n",
    "    \"acquisition_cost\",\n",
    "    \"twitter_spend_smoothed\",\n",
    "    \"facebook_spend_smoothed\",\n",
    "    \"radio_spend_smoothed\",\n",
    "    \"tv_spend_smoothed\",\n",
    "    \"billboards_spend_smoothed\",\n",
    "    \"youtube_spend_smoothed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @main.command()\n",
    "def duckdb():\n",
    "    driver = hamilton.driver.Driver(\n",
    "        {\"db_path\": \"./test_data/database.duckdb\"}, load_data_duckdb, prep_data\n",
    "    )\n",
    "    print(driver.execute(VARS))\n",
    "    # driver.visualize_execution(VARS, './duckdb_execution_graph', {\"format\": \"png\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            total_signups  total_churn  total_marketing_spend  \\\n",
      "date                                                            \n",
      "2020-01-01           1947          203           52730.560003   \n",
      "2020-01-02           1910          197           49279.312391   \n",
      "2020-01-03           1899          203           51302.996119   \n",
      "2020-01-04           1930          197           56406.767429   \n",
      "2020-01-05           1893          200           62571.780395   \n",
      "...                   ...          ...                    ...   \n",
      "2022-08-28           2827          191          363933.708589   \n",
      "2022-08-29           2843          192          368187.139781   \n",
      "2022-08-30           2822          192          364502.996497   \n",
      "2022-08-31           2870          184          361548.842342   \n",
      "2022-09-01           2853          185          357315.802822   \n",
      "\n",
      "            acquisition_cost  twitter_spend_smoothed  facebook_spend_smoothed  \\\n",
      "date                                                                            \n",
      "2020-01-01         27.082979                0.000000                 0.000000   \n",
      "2020-01-02         25.800687                0.000000                 0.000000   \n",
      "2020-01-03         27.015796                0.000000                 0.000000   \n",
      "2020-01-04         29.226304                0.000000                 0.000000   \n",
      "2020-01-05         33.054295                0.000000                 0.000000   \n",
      "...                      ...                     ...                      ...   \n",
      "2022-08-28        128.734952           119720.253147             96123.914351   \n",
      "2022-08-29        129.506556           120202.788392             95909.302910   \n",
      "2022-08-30        129.164776           120732.077431             96035.431620   \n",
      "2022-08-31        125.975206           121276.011602             96364.649955   \n",
      "2022-09-01        125.242132           121910.888572             96362.987882   \n",
      "\n",
      "            radio_spend_smoothed  tv_spend_smoothed  \\\n",
      "date                                                  \n",
      "2020-01-01              0.000000           0.000000   \n",
      "2020-01-02              0.000000           0.000000   \n",
      "2020-01-03              0.000000           0.000000   \n",
      "2020-01-04              0.000000           0.000000   \n",
      "2020-01-05              0.000000           0.000000   \n",
      "...                          ...                ...   \n",
      "2022-08-28          13640.112643       67931.752455   \n",
      "2022-08-29          13731.030787       67883.385906   \n",
      "2022-08-30          13801.817606       67874.037430   \n",
      "2022-08-31          13815.628266       67796.627318   \n",
      "2022-09-01          13826.582827       67695.406002   \n",
      "\n",
      "            billboards_spend_smoothed  youtube_spend_smoothed  \n",
      "date                                                           \n",
      "2020-01-01                   0.000000                0.000000  \n",
      "2020-01-02                   0.000000                0.000000  \n",
      "2020-01-03                   0.000000                0.000000  \n",
      "2020-01-04                   0.000000                0.000000  \n",
      "2020-01-05                   0.000000                0.000000  \n",
      "...                               ...                     ...  \n",
      "2022-08-28                2370.658271           119720.253147  \n",
      "2022-08-29                2088.525551           120202.788392  \n",
      "2022-08-30                1649.969593           120732.077431  \n",
      "2022-08-31                1337.251853           121276.011602  \n",
      "2022-09-01                 997.866137           121910.888572  \n",
      "\n",
      "[975 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\obeng\\Desktop\\open_source\\venv\\Lib\\site-packages\\hamilton\\plugins\\pandas_extensions.py:249: FutureWarning: The 'keep_date_col' keyword in pd.read_csv is deprecated and will be removed in a future version. Explicitly remove unwanted columns after parsing instead.\n",
      "  df = pd.read_csv(self.path, **self._get_loading_kwargs())\n",
      "c:\\Users\\obeng\\Desktop\\open_source\\venv\\Lib\\site-packages\\hamilton\\plugins\\pandas_extensions.py:249: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(self.path, **self._get_loading_kwargs())\n",
      "c:\\Users\\obeng\\Desktop\\open_source\\venv\\Lib\\site-packages\\hamilton\\plugins\\pandas_extensions.py:249: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  df = pd.read_csv(self.path, **self._get_loading_kwargs())\n",
      "c:\\Users\\obeng\\Desktop\\open_source\\venv\\Lib\\site-packages\\hamilton\\plugins\\pandas_extensions.py:249: FutureWarning: The 'keep_date_col' keyword in pd.read_csv is deprecated and will be removed in a future version. Explicitly remove unwanted columns after parsing instead.\n",
      "  df = pd.read_csv(self.path, **self._get_loading_kwargs())\n",
      "c:\\Users\\obeng\\Desktop\\open_source\\venv\\Lib\\site-packages\\hamilton\\plugins\\pandas_extensions.py:249: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(self.path, **self._get_loading_kwargs())\n",
      "c:\\Users\\obeng\\Desktop\\open_source\\venv\\Lib\\site-packages\\hamilton\\plugins\\pandas_extensions.py:249: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  df = pd.read_csv(self.path, **self._get_loading_kwargs())\n",
      "c:\\Users\\obeng\\Desktop\\open_source\\venv\\Lib\\site-packages\\hamilton\\plugins\\pandas_extensions.py:249: FutureWarning: The 'keep_date_col' keyword in pd.read_csv is deprecated and will be removed in a future version. Explicitly remove unwanted columns after parsing instead.\n",
      "  df = pd.read_csv(self.path, **self._get_loading_kwargs())\n",
      "c:\\Users\\obeng\\Desktop\\open_source\\venv\\Lib\\site-packages\\hamilton\\plugins\\pandas_extensions.py:249: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(self.path, **self._get_loading_kwargs())\n",
      "c:\\Users\\obeng\\Desktop\\open_source\\venv\\Lib\\site-packages\\hamilton\\plugins\\pandas_extensions.py:249: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  df = pd.read_csv(self.path, **self._get_loading_kwargs())\n"
     ]
    }
   ],
   "source": [
    "# @main.command()\n",
    "def csv():\n",
    "    driver = hamilton.driver.Driver({\"db_path\": \"test_data\"}, load_data_csv, prep_data)\n",
    "    print(driver.execute(VARS))\n",
    "    # driver.visualize_execution(VARS, \"./csv_execution_graph\", {\"format\": \"png\"})\n",
    "\n",
    "csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            total_signups  total_churn  total_marketing_spend  \\\n",
      "date                                                            \n",
      "2022-08-03           2613          213          352562.280870   \n",
      "2022-08-04           2625          216          355564.902400   \n",
      "2022-08-05           2613          212          353811.045380   \n",
      "2022-08-06           2606          214          354899.924090   \n",
      "2022-08-07           2599          209          354891.300149   \n",
      "2022-08-08           2668          212          357514.248166   \n",
      "2022-08-09           2674          214          351627.165746   \n",
      "2022-08-10           2725          217          350941.982457   \n",
      "2022-08-11           2744          212          350736.588485   \n",
      "2022-08-12           2749          206          350944.306317   \n",
      "\n",
      "            acquisition_cost  twitter_spend_smoothed  facebook_spend_smoothed  \\\n",
      "date                                                                            \n",
      "2022-08-03        134.926246                0.000000                 0.000000   \n",
      "2022-08-04        135.453296                0.000000                 0.000000   \n",
      "2022-08-05        135.404151                0.000000                 0.000000   \n",
      "2022-08-06        136.185696                0.000000                 0.000000   \n",
      "2022-08-07        136.549173                0.000000                 0.000000   \n",
      "2022-08-08        134.000843                0.000000                 0.000000   \n",
      "2022-08-09        131.498566           115461.750752            102420.254555   \n",
      "2022-08-10        128.786049           115410.481211            102005.647728   \n",
      "2022-08-11        127.819456           115461.364832            101589.002831   \n",
      "2022-08-12        127.662534           115686.617590            101618.669361   \n",
      "\n",
      "            radio_spend_smoothed  tv_spend_smoothed  \\\n",
      "date                                                  \n",
      "2022-08-03                   0.0                0.0   \n",
      "2022-08-04                   0.0                0.0   \n",
      "2022-08-05                   0.0                0.0   \n",
      "2022-08-06                   0.0                0.0   \n",
      "2022-08-07                   0.0                0.0   \n",
      "2022-08-08                   0.0                0.0   \n",
      "2022-08-09                   0.0                0.0   \n",
      "2022-08-10                   0.0                0.0   \n",
      "2022-08-11                   0.0                0.0   \n",
      "2022-08-12                   0.0                0.0   \n",
      "\n",
      "            billboards_spend_smoothed  youtube_spend_smoothed  \n",
      "date                                                           \n",
      "2022-08-03                   0.000000                0.000000  \n",
      "2022-08-04                   0.000000                0.000000  \n",
      "2022-08-05                   0.000000                0.000000  \n",
      "2022-08-06                   0.000000                0.000000  \n",
      "2022-08-07                   0.000000                0.000000  \n",
      "2022-08-08                   0.000000                0.000000  \n",
      "2022-08-09                1943.742110           115461.750752  \n",
      "2022-08-10                2205.101803           115410.481211  \n",
      "2022-08-11                2394.622409           115461.364832  \n",
      "2022-08-12                2361.296779           115686.617590  \n"
     ]
    }
   ],
   "source": [
    "# @main.command()\n",
    "def mock():\n",
    "    driver = hamilton.driver.Driver({}, load_data_mock, prep_data)\n",
    "    print(driver.execute(VARS))\n",
    "    # driver.visualize_execution(VARS, './mock_execution_graph', {\"format\": \"png\"})\n",
    "\n",
    "mock()\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
