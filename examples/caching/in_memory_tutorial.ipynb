{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to install dependencies\n",
    "%pip install sf-hamilton[visualization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-memory caching tutorial [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dagworks-inc/hamilton/blob/main/examples/caching/in_memory_tutorial.ipynb) [![GitHub badge](https://img.shields.io/badge/github-view_source-2b3137?logo=github)](https://github.com/dagworks-inc/hamilton/blob/main/examples/caching/in_memory_tutorial.ipynb)\n",
    "\n",
    "\n",
    "This notebook shows how to use in-memory caching, which allows to cache results between runs without writing to disk. This uses the `InMemoryResultStore` and `InMemoryMetadataStore` classes.\n",
    "\n",
    "> ⛔ In-memory caching can consume a lot of memory if you're using storing large results. Selectively caching nodes is recommended.\n",
    "\n",
    "If you're new to caching, you should take a look at the [caching tutorial](./tutorial.ipynb) first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Throughout this tutorial, we'll be using the Hamilton notebook extension to define dataflows directly in the notebook ([see tutorial](https://github.com/DAGWorks-Inc/hamilton/blob/main/examples/jupyter_notebook_magic/example.ipynb)).\n",
    "\n",
    "Then, we get the logger for caching and clear previously cached results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import shutil\n",
    "\n",
    "# avoid loading all available plugins for fast startup time\n",
    "from hamilton import registry\n",
    "registry.disable_autoload()\n",
    "registry.load_extension(\"pandas\")\n",
    "\n",
    "from hamilton import driver\n",
    "\n",
    "# load the notebook extension\n",
    "%reload_ext hamilton.plugins.jupyter_magic\n",
    "\n",
    "logger = logging.getLogger(\"hamilton.caching\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "shutil.rmtree(\"./.hamilton_cache\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a dataflow\n",
    "We define a simple dataflow that loads a dataframe of transactions, filters by date, converts currency to USD, and sums the amount per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cell_to_module dataflow_module --display\n",
    "import pandas as pd\n",
    "\n",
    "DATA = {\n",
    "    \"cities\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Montréal\", \"Vancouver\"],\n",
    "    \"date\": [\"2024-09-13\", \"2024-09-12\", \"2024-09-11\", \"2024-09-11\", \"2024-09-09\"],\n",
    "    \"amount\": [478.23, 251.67, 989.34, 742.14, 584.56],\n",
    "    \"country\": [\"USA\", \"USA\", \"USA\", \"Canada\", \"Canada\"],\n",
    "    \"currency\": [\"USD\", \"USD\", \"USD\", \"CAD\", \"CAD\"],\n",
    "}\n",
    "\n",
    "def raw_data() -> pd.DataFrame:\n",
    "    \"\"\"Loading raw data. This simulates loading from a file, database, or external service.\"\"\"\n",
    "    return pd.DataFrame(DATA)\n",
    "\n",
    "def processed_data(raw_data: pd.DataFrame, cutoff_date: str) -> pd.DataFrame:\n",
    "    \"\"\"Filter out rows before cutoff date and convert currency to USD.\"\"\"\n",
    "    df = raw_data.loc[raw_data.date > cutoff_date].copy()\n",
    "    df[\"amound_in_usd\"] = df[\"amount\"]\n",
    "    df.loc[df.country == \"Canada\", \"amound_in_usd\"] *= 0.71  \n",
    "    df.loc[df.country == \"Brazil\", \"amound_in_usd\"] *= 0.18  # <- LINE ADDED\n",
    "    df.loc[df.country == \"Mexico\", \"amound_in_usd\"] *= 0.05  # <- LINE ADDED\n",
    "    return df\n",
    "\n",
    "def amount_per_country(processed_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Sum the amount in USD per country\"\"\"\n",
    "    return processed_data.groupby(\"country\")[\"amound_in_usd\"].sum().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-memory caching\n",
    "To use in-memory caching, pass `InMemoryResultStore` and `InMemoryMetadataStore` to  `Builder().with_cache()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamilton.caching.stores.memory import InMemoryMetadataStore, InMemoryResultStore\n",
    "\n",
    "dr = (\n",
    "    driver.Builder()\n",
    "    .with_modules(dataflow_module)\n",
    "    .with_cache(\n",
    "        result_store=InMemoryResultStore(),\n",
    "        metadata_store=InMemoryMetadataStore(),\n",
    "    )\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution 1\n",
    "For execution 1, we see that all nodes are executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dr.execute([\"processed_data\"], inputs={\"cutoff_date\": \"2024-09-01\"})\n",
    "print()\n",
    "print(results[\"processed_data\"].head())\n",
    "dr.cache.view_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution 2\n",
    "For execution 2, we see that all nodes are retrieved from cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dr.execute([\"processed_data\"], inputs={\"cutoff_date\": \"2024-09-01\"})\n",
    "print()\n",
    "print(results[\"processed_data\"].head())\n",
    "dr.cache.view_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting in-memory data\n",
    "\n",
    "Now, we import `SQLiteMetadataStore` and `FileResultStore` to persist the data to disk. We access the in-memory stores via `dr.cache.result_store` and `dr.cache.metadata_store` and call the `.persist_to()` method on each.\n",
    "\n",
    "After executing the cell, you should see a new directory `./.persisted_cache` with results and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamilton.caching.stores.sqlite import SQLiteMetadataStore\n",
    "from hamilton.caching.stores.file import FileResultStore\n",
    "\n",
    "path = \"./.persisted_cache\"\n",
    "on_disk_results = FileResultStore(path=path)\n",
    "on_disk_metadata = SQLiteMetadataStore(path=path)\n",
    "\n",
    "dr.cache.result_store.persist_to(on_disk_results)\n",
    "dr.cache.metadata_store.persist_to(on_disk_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading persisted data\n",
    "\n",
    "Now, we create a new `Driver`. Instead of starting with empty in-memory stores, we will load the previously persisted results by calling `.load_from()` on the `InMemoryResultStore` and `InMemoryMetadataStore` classes.\n",
    "\n",
    "For `InMemoryResultStore.load_from()`, we must provide a `MetadataStore` or a list of `data_version` to load results for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = (\n",
    "    driver.Builder()\n",
    "    .with_modules(dataflow_module)\n",
    "    .with_cache(\n",
    "        result_store=InMemoryResultStore.load_from(\n",
    "            on_disk_results,\n",
    "            metadata_store=on_disk_metadata,\n",
    "        ),\n",
    "        metadata_store=InMemoryMetadataStore.load_from(on_disk_metadata),\n",
    "    )\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the size of the metadata store to show it contains 2 entries (one for `raw_data` and another for `processed_data`). Also, we see that results load from `FileResultStore`are successfully retrieved from the in-memory stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dr.cache.metadata_store.size)\n",
    "\n",
    "results = dr.execute([\"processed_data\"], inputs={\"cutoff_date\": \"2024-09-01\"})\n",
    "print()\n",
    "print(results[\"processed_data\"].head())\n",
    "dr.cache.view_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cases\n",
    "\n",
    "In-memory caching can be useful when you're doing a lot of experimentation in a notebook or an interactive session and don't want to persist results for future use. \n",
    "\n",
    "It can also speed up execution in some cases because you're no longer doing read/write to disk for each node execution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
