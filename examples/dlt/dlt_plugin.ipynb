{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dlt plugin for Hamilton\n",
    "This notebook shows how to use Hamilton [materializers](https://hamilton.dagworks.io/en/latest/concepts/materialization/) to move data between Hamilton and dlt.\n",
    "\n",
    "Content:\n",
    "1. Defining an illustrative Hamilton dataflow\n",
    "2. `DataSaver`: save Hamilton results to a [dlt Destination](https://dlthub.com/docs/dlt-ecosystem/destinations/)\n",
    "3. `DataLoader`: load data from a [dlt Resource](https://dlthub.com/docs/dlt-ecosystem/verified-sources/) (a single table from a Source) into a Hamilton node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext hamilton.plugins.jupyter_magic\n",
    "\n",
    "import dlt\n",
    "from hamilton import driver\n",
    "from hamilton.io.materialization import to, from_\n",
    "from hamilton.plugins import dlt_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"334pt\" height=\"295pt\"\n",
       " viewBox=\"0.00 0.00 334.00 295.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 291)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-291 330,-291 330,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster__legend</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"36.5,-147 36.5,-279 132.5,-279 132.5,-147 36.5,-147\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.5\" y=\"-263.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Legend</text>\n",
       "</g>\n",
       "<!-- print_df_head -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>print_df_head</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M314,-64C314,-64 210,-64 210,-64 204,-64 198,-58 198,-52 198,-52 198,-12 198,-12 198,-6 204,0 210,0 210,0 314,0 314,0 320,0 326,-6 326,-12 326,-12 326,-52 326,-52 326,-58 320,-64 314,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"209\" y=\"-42.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">print_df_head</text>\n",
       "<text text-anchor=\"start\" x=\"223.5\" y=\"-14.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">DataFrame</text>\n",
       "</g>\n",
       "<!-- table -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>table</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M122,-137C122,-137 47,-137 47,-137 41,-137 35,-131 35,-125 35,-125 35,-85 35,-85 35,-79 41,-73 47,-73 47,-73 122,-73 122,-73 128,-73 134,-79 134,-85 134,-85 134,-125 134,-125 134,-131 128,-137 122,-137\"/>\n",
       "<text text-anchor=\"start\" x=\"64\" y=\"-115.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">table</text>\n",
       "<text text-anchor=\"start\" x=\"46\" y=\"-87.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">DataFrame</text>\n",
       "</g>\n",
       "<!-- _print_df_head_inputs -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>_print_df_head_inputs</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"169,-54.5 0,-54.5 0,-9.5 169,-9.5 169,-54.5\"/>\n",
       "<text text-anchor=\"start\" x=\"15.5\" y=\"-27.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">external</text>\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-27.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">DataFrame</text>\n",
       "</g>\n",
       "<!-- _print_df_head_inputs&#45;&gt;print_df_head -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_print_df_head_inputs&#45;&gt;print_df_head</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.14,-32C175.36,-32 181.61,-32 187.76,-32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"188,-35.5 198,-32 188,-28.5 188,-35.5\"/>\n",
       "</g>\n",
       "<!-- input -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>input</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"114,-247.5 55,-247.5 55,-210.5 114,-210.5 114,-247.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.5\" y=\"-225.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">input</text>\n",
       "</g>\n",
       "<!-- function -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>function</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M112.5,-192.5C112.5,-192.5 56.5,-192.5 56.5,-192.5 50.5,-192.5 44.5,-186.5 44.5,-180.5 44.5,-180.5 44.5,-167.5 44.5,-167.5 44.5,-161.5 50.5,-155.5 56.5,-155.5 56.5,-155.5 112.5,-155.5 112.5,-155.5 118.5,-155.5 124.5,-161.5 124.5,-167.5 124.5,-167.5 124.5,-180.5 124.5,-180.5 124.5,-186.5 118.5,-192.5 112.5,-192.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.5\" y=\"-170.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">function</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7febfc391990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%cell_to_module -m my_module -d\n",
    "import pandas as pd\n",
    "\n",
    "def table() -> pd.DataFrame:\n",
    "    return pd.DataFrame([{\"C\": 1}, {\"C\": 2}])\n",
    "\n",
    "def print_df_head(external: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"from print_df_head:\\n\", external.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = driver.Builder().with_modules(my_module).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSaver\n",
    "With \"Extract, Transform, Load\" (ETL) as frame of reference, here, the Hamilton dataflow is responsible for Transform, and `DltDestination` for Load.\n",
    "\n",
    "\n",
    "Start by defining a dlt `Pipeline` that uses your chosen dlt Destination. This is regular dlt code that you will pass to Hamilton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver_pipeline = dlt.pipeline(pipeline_name=\"saver_pipe\", destination=\"duckdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single dependency\n",
    "Define the materializer with `to.dlt()` the example below shows required arguments. You specify an `id` for the materializer and `dependencies` includes the name of a single Hamilton node. Then, specify a `table_name` for the destination and pass the `pipeline`. \n",
    "\n",
    "The [other keyword arguments](https://dlthub.com/docs/api_reference/pipeline/__init__#run) for `dlt.pipeline.run()` are accepted and allow specifying incremental loading, table schema annotation, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': {'pipeline_name': 'saver_pipe'}, 'metrics': [{'started_at': DateTime(2024, 4, 14, 21, 56, 41, 147097, tzinfo=Timezone('UTC')), 'finished_at': DateTime(2024, 4, 14, 21, 56, 41, 320724, tzinfo=Timezone('UTC')), 'load_id': '1713131800.765432'}], 'destination_type': 'dlt.destinations.duckdb', 'destination_displayable_credentials': 'duckdb:////home/tjean/projects/dagworks/hamilton/examples/dlt/saver_pipe.duckdb', 'destination_name': 'duckdb', 'environment': None, 'staging_type': None, 'staging_name': None, 'staging_displayable_credentials': None, 'destination_fingerprint': '', 'dataset_name': 'saver_pipe_dataset', 'loads_ids': ['1713131800.765432'], 'load_packages': [{'load_id': '1713131800.765432', 'package_path': '/home/tjean/.dlt/pipelines/saver_pipe/load/loaded/1713131800.765432', 'state': 'loaded', 'completed_at': DateTime(2024, 4, 14, 21, 56, 41, 306600, tzinfo=Timezone('UTC')), 'jobs': [{'state': 'completed_jobs', 'file_path': '/home/tjean/.dlt/pipelines/saver_pipe/load/loaded/1713131800.765432/completed_jobs/my_table.a17fa20182.0.parquet', 'file_size': 574, 'created_at': DateTime(2024, 4, 14, 21, 56, 40, 776600, tzinfo=Timezone('UTC')), 'elapsed': 0.5299997329711914, 'failed_message': None, 'table_name': 'my_table', 'file_id': 'a17fa20182', 'retry_count': 0, 'file_format': 'parquet'}], 'schema_hash': 'UE8l1iVz3xnHM+zYpjm8Bqd+3m6rDG++zNubWIUyecg=', 'schema_name': 'saver_pipe', 'tables': []}], 'first_run': False, 'started_at': DateTime(2024, 4, 14, 21, 56, 41, 147097, tzinfo=Timezone('UTC')), 'finished_at': DateTime(2024, 4, 14, 21, 56, 41, 320724, tzinfo=Timezone('UTC'))}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"319pt\" height=\"291pt\"\n",
       " viewBox=\"0.00 0.00 319.00 291.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 287)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-287 315,-287 315,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster__legend</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"8,-86 8,-275 129,-275 129,-86 8,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.5\" y=\"-259.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Legend</text>\n",
       "</g>\n",
       "<!-- saver_node -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>saver_node</title>\n",
       "<path fill=\"#ffc857\" stroke=\"black\" d=\"M311,-80C311,-84.41 274.92,-88 230.5,-88 186.08,-88 150,-84.41 150,-80 150,-80 150,-8 150,-8 150,-3.59 186.08,0 230.5,0 274.92,0 311,-3.59 311,-8 311,-8 311,-80 311,-80\"/>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M311,-80C311,-75.59 274.92,-72 230.5,-72 186.08,-72 150,-75.59 150,-80\"/>\n",
       "<text text-anchor=\"start\" x=\"185.5\" y=\"-54.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">saver_node</text>\n",
       "<text text-anchor=\"start\" x=\"161\" y=\"-26.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">DltDestinationSaver</text>\n",
       "</g>\n",
       "<!-- table -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>table</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M106,-76C106,-76 31,-76 31,-76 25,-76 19,-70 19,-64 19,-64 19,-24 19,-24 19,-18 25,-12 31,-12 31,-12 106,-12 106,-12 112,-12 118,-18 118,-24 118,-24 118,-64 118,-64 118,-70 112,-76 106,-76\"/>\n",
       "<text text-anchor=\"start\" x=\"48\" y=\"-54.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">table</text>\n",
       "<text text-anchor=\"start\" x=\"30\" y=\"-26.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">DataFrame</text>\n",
       "</g>\n",
       "<!-- table&#45;&gt;saver_node -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>table&#45;&gt;saver_node</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.37,-44C125.26,-44 132.51,-44 139.87,-44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"139.96,-47.5 149.96,-44 139.96,-40.5 139.96,-47.5\"/>\n",
       "</g>\n",
       "<!-- function -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>function</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M96.5,-243.5C96.5,-243.5 40.5,-243.5 40.5,-243.5 34.5,-243.5 28.5,-237.5 28.5,-231.5 28.5,-231.5 28.5,-218.5 28.5,-218.5 28.5,-212.5 34.5,-206.5 40.5,-206.5 40.5,-206.5 96.5,-206.5 96.5,-206.5 102.5,-206.5 108.5,-212.5 108.5,-218.5 108.5,-218.5 108.5,-231.5 108.5,-231.5 108.5,-237.5 102.5,-243.5 96.5,-243.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.5\" y=\"-221.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">function</text>\n",
       "</g>\n",
       "<!-- output -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>output</title>\n",
       "<path fill=\"#ffc857\" stroke=\"black\" d=\"M90.5,-188.5C90.5,-188.5 46.5,-188.5 46.5,-188.5 40.5,-188.5 34.5,-182.5 34.5,-176.5 34.5,-176.5 34.5,-163.5 34.5,-163.5 34.5,-157.5 40.5,-151.5 46.5,-151.5 46.5,-151.5 90.5,-151.5 90.5,-151.5 96.5,-151.5 102.5,-157.5 102.5,-163.5 102.5,-163.5 102.5,-176.5 102.5,-176.5 102.5,-182.5 96.5,-188.5 90.5,-188.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.5\" y=\"-166.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">output</text>\n",
       "</g>\n",
       "<!-- materializer -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>materializer</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M121,-130.26C121,-132.26 97.47,-133.88 68.5,-133.88 39.53,-133.88 16,-132.26 16,-130.26 16,-130.26 16,-97.74 16,-97.74 16,-95.74 39.53,-94.12 68.5,-94.12 97.47,-94.12 121,-95.74 121,-97.74 121,-97.74 121,-130.26 121,-130.26\"/>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M121,-130.26C121,-128.27 97.47,-126.65 68.5,-126.65 39.53,-126.65 16,-128.27 16,-130.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.5\" y=\"-110.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">materializer</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7febb4322cb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "materializers = [\n",
    "    to.dlt(\n",
    "        id=\"saver_node\",\n",
    "        dependencies=[\"table\"],\n",
    "        table_name=\"my_table\",\n",
    "        pipeline=saver_pipeline,\n",
    "    )\n",
    "]\n",
    "metadata, _ = dr.materialize(*materializers)\n",
    "print(metadata[\"saver_node\"])\n",
    "dr.visualize_materialization(*materializers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "With ETL as a frame of reference, the `DataLoader` uses dlt to run the \"Extract\" step for the passed dlt `Resource`. \n",
    "\n",
    "Internally, it creates a temporary dlt Pipeline to run the extract and normalize steps then reads the files in-memory. The dlt Pipeline is then deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a mock dlt Source for demo purposes\n",
    "\n",
    "from typing import Iterable\n",
    "from dlt.extract import DltResource\n",
    "from dlt.common.typing import TDataItem\n",
    "\n",
    "@dlt.source\n",
    "def mock_source() -> Iterable[DltResource]:\n",
    "    iterable_data = [{\"col\": 1}, {\"col\": 2}, {\"col\": 3}] * 100\n",
    "    \n",
    "    @dlt.resource\n",
    "    def mock_resource() -> Iterable[TDataItem]:\n",
    "        yield from iterable_data\n",
    "        \n",
    "    yield mock_resource\n",
    "        \n",
    "        \n",
    "my_mock_source = mock_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single resource\n",
    "To define the materializer, give it a `target` Hamilton node and pass a dlt Resource to `resource`. When working with a dlt Source, you can access individual resources via the dictionary `Source.resource[RESOURCE_NAME]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from print_df_head:\n",
      "    col        _dlt_load_id         _dlt_id\n",
      "0    1  1713131801.3954566  pIOVDF0PSQez4g\n",
      "1    2  1713131801.3954566  V39tnCZ5OHJS8A\n",
      "2    3  1713131801.3954566  Neg2YxZXqbtDdg\n",
      "3    1  1713131801.3954566  18GzdWmzRuFGFQ\n",
      "4    2  1713131801.3954566  fRs/oHZpBQbEIg\n"
     ]
    }
   ],
   "source": [
    "materializers = [\n",
    "    from_.dlt(\n",
    "        target=\"external\",\n",
    "        resource=my_mock_source.resources[\"mock_resource\"],\n",
    "    ),\n",
    "]\n",
    "\n",
    "metadata, _ = dr.materialize(\n",
    "    *materializers,\n",
    "    additional_vars=[\"print_df_head\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
