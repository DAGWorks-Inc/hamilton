{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!pip install sentence_transformers datasets lancedb sf-hamilton -qU"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NER Powered Semantic Search\n",
    "\n",
    "This notebook shows how to use Named Entity Recognition (NER) for vector search with LanceDB & Hamilton. We will:\n",
    "\n",
    "1. Extract named entities from text.\n",
    "2. Store them in a LanceDB as metadata (alongside respective text & embedding vectors).\n",
    "3. We extract named entities from incoming queries and use them to filter and search only through records containing these named entities.\n",
    "\n",
    "This is particularly helpful if you want to restrict the search to records that contain information about the named entities that are also found within the query.\n",
    "\n",
    "Let's get started."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f16043d07abadc81"
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext hamilton.plugins.jupyter_magic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T22:52:53.305913Z",
     "start_time": "2024-04-10T22:52:50.668455Z"
    }
   },
   "id": "c3779bcd738db9e0",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%cell_to_module -m ner_search --display --config '{\"mode\":\"ingestion\"}'\n",
    "import lancedb\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines import base\n",
    "from hamilton.htypes import Parallelizable, Collect\n",
    "from hamilton.function_modifiers import config\n",
    "import numpy as np\n",
    "\n",
    "def medium_articles() -> pd.DataFrame:\n",
    "    # load the dataset and convert to pandas dataframe\n",
    "    df = load_dataset(\n",
    "        \"fabiochiu/medium-articles\", data_files=\"medium_articles.csv\", split=\"train\"\n",
    "    ).to_pandas()\n",
    "    return df\n",
    "\n",
    "def sampled_articles(medium_articles: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = medium_articles.dropna().sample(20000, random_state=32)\n",
    "    # select first 1000 characters\n",
    "    df[\"text\"] = df[\"text\"].str[:1000]\n",
    "    # join article title and the text\n",
    "    df[\"title_text\"] = df[\"title\"] + \". \" + df[\"text\"]\n",
    "    return df\n",
    "\n",
    "def device() -> int:\n",
    "    return torch.cuda.current_device() if torch.cuda.is_available() else None\n",
    "\n",
    "\n",
    "def model_id() -> str:\n",
    "    # To extract named entities, we will use a NER model finetuned on a BERT-base model.\n",
    "    # The model can be loaded from the HuggingFace model hub\n",
    "    return \"dslim/bert-base-NER\"\n",
    "\n",
    "def tokenizer(model_id: str) -> AutoTokenizer:\n",
    "    \"\"\"load the tokenizer from huggingface\"\"\"\n",
    "    print(\"Loading the tokenizer\")\n",
    "    return AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "def model(model_id: str) -> object:\n",
    "    \"\"\"load the NER model from huggingface\"\"\"\n",
    "    print(\"Loading the model\")\n",
    "    return  AutoModelForTokenClassification.from_pretrained(model_id)\n",
    "\n",
    "# load the tokenizer and model into a NER pipeline\n",
    "def ner_pipeline(model: object, tokenizer: AutoTokenizer, device: int) -> base.Pipeline:\n",
    "    print(\"Loading the ner_pipeline\")\n",
    "    return pipeline(\n",
    "        \"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"max\", device=device\n",
    "    )\n",
    "\n",
    "def retriever(device: int) -> SentenceTransformer:\n",
    "    \"\"\"A retriever model is used to embed passages (article title + first 1000 characters) and queries. It creates embeddings such that queries and passages with similar meanings are close in the vector space. We will use a sentence-transformer model as our retriever. The model can be loaded as follows:\n",
    "    \"\"\"\n",
    "    print(\"Loading the retriever model\")\n",
    "    return SentenceTransformer(\n",
    "    \"flax-sentence-embeddings/all_datasets_v3_mpnet-base\", device=device\n",
    "    )\n",
    "\n",
    "\n",
    "def db() -> lancedb.DBConnection:\n",
    "    return lancedb.connect(\"./.lancedb\")\n",
    "\n",
    "def batch_size() -> int:\n",
    "    # we will use batches of 64\n",
    "    return 64\n",
    "\n",
    "def batch(sampled_articles: pd.DataFrame, batch_size: int) -> Parallelizable[pd.DataFrame]:\n",
    "    # split the articles into batches\n",
    "    for i in range(0, len(sampled_articles), batch_size):\n",
    "        # find end of batch\n",
    "        i_end = min(i + batch_size, len(sampled_articles))\n",
    "        # extract batch\n",
    "        batch = sampled_articles.iloc[i:i_end].copy()\n",
    "        yield batch\n",
    "\n",
    "def title_text(batch: pd.DataFrame) -> list[str]:\n",
    "    return batch[\"title_text\"].tolist()\n",
    "\n",
    "def embeddings(title_text: list[str], retriever: SentenceTransformer) -> list[list[float]]:\n",
    "    # generate embeddings for batch\n",
    "    return retriever.encode(title_text).tolist()\n",
    "\n",
    "def entities(title_text: list[str], ner_pipeline: base.Pipeline) -> list[list[str]]:\n",
    "    # extract named entities using the NER pipeline\n",
    "    extracted_batch = ner_pipeline(title_text)\n",
    "    entities = []\n",
    "    # loop through the results and only select the entity names\n",
    "    for text in extracted_batch:\n",
    "        ne = [entity[\"word\"] for entity in text]\n",
    "        entities.append(ne)\n",
    "    return entities\n",
    "\n",
    "def named_entities(entities: list[list[str]]) -> list[list[str]]:\n",
    "    return [list(set(entity)) for entity in entities]\n",
    "\n",
    "def meta(batch: pd.DataFrame, named_entities: list[list[str]]) -> list[dict]:\n",
    "    # create a dataframe we want for metadata\n",
    "    df = batch.drop(\"title_text\", axis=1)\n",
    "    df[\"named_entities\"] = named_entities\n",
    "    return df.to_dict(orient=\"records\")\n",
    "\n",
    "def to_upsert(embeddings: list[list[float]],\n",
    "              meta: list[dict],\n",
    "              named_entities: list[list[str]]) -> list[tuple[list[float], dict, list[str]]]:\n",
    "    return list(zip(embeddings, meta, named_entities))\n",
    "\n",
    "def data(to_upsert: Collect[list[tuple[list[float], dict, list[str]]]]) -> list[dict]:\n",
    "    data = []\n",
    "    for result in to_upsert:\n",
    "        for emb, meta, entity in result:\n",
    "            temp = dict()\n",
    "            temp[\"vector\"] = np.array(emb)\n",
    "            temp[\"metadata\"] = meta\n",
    "            temp[\"named_entities\"] = entity\n",
    "            data.append(temp)\n",
    "    return data\n",
    "\n",
    "@config.when(mode=\"ingestion\")\n",
    "def lancedb_table__ingestion(db: lancedb.DBConnection, data: list[dict], table_name: str = \"tw\") -> lancedb.table.Table:\n",
    "    tbl = db.create_table(table_name, data)\n",
    "    return tbl\n",
    "\n",
    "@config.when(mode=\"query\")\n",
    "def lancedb_table__query(db: lancedb.DBConnection, table_name: str = \"tw\") -> lancedb.table.Table:\n",
    "    tbl = db.open_table(table_name)\n",
    "    return tbl\n",
    "\n",
    "def search_lancedb(query: str,\n",
    "                   ner_pipeline: base.Pipeline,\n",
    "                   retriever: SentenceTransformer,\n",
    "                   lancedb_table: lancedb.table.Table) -> dict:\n",
    "    # extract named entities from the query\n",
    "    ne = entities([query], ner_pipeline)[0]  # Note: we're directly calling the function here.\n",
    "    # create embeddings for the query\n",
    "    xq = retriever.encode(query).tolist()\n",
    "    # query the lancedb table while applying named entity filter\n",
    "    xc = lancedb_table.search(xq).to_list()\n",
    "    # extract article titles from the search result\n",
    "    r = [\n",
    "        x[\"metadata\"][\"title\"]\n",
    "        for x in xc\n",
    "        for i in x[\"metadata\"][\"named_entities\"]\n",
    "        if i in ne\n",
    "    ]\n",
    "    return {\"Extracted Named Entities\": ne, \"Result\": r}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T00:37:00.900505Z",
     "start_time": "2024-04-11T00:37:00.359482Z"
    }
   },
   "id": "68bbb0d987a85d06",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from hamilton import driver\n",
    "dr = (\n",
    "    driver.Builder()\n",
    "    .with_config({\"mode\": \"ingestion\"})\n",
    "    .with_modules(ner_search)\n",
    "    .enable_dynamic_execution(allow_experimental_mode=True)\n",
    "    .build()\n",
    ")\n",
    "results = dr.execute([\"retriever\", \"ner_pipeline\", \"data\", \"lancedb_table\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T00:11:41.091151Z",
     "start_time": "2024-04-10T23:47:47.710760Z"
    }
   },
   "id": "9dd70c2ceecbbb71",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dr.execute([\"search_lancedb\"], \n",
    "           inputs={\"query\": \"How Data is changing the world?\"},\n",
    "           overrides=results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T00:11:41.103254Z",
     "start_time": "2024-04-11T00:11:41.099972Z"
    }
   },
   "id": "e5686dd7ee49b2e4",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dr_inference_only = (\n",
    "    driver.Builder()\n",
    "    .with_config({\"mode\": \"query\"})\n",
    "    .with_modules(ner_search)\n",
    "    .build()\n",
    ")\n",
    "dr_inference_only.execute([\"search_lancedb\"], \n",
    "           inputs={\"query\": \"How Data is changing the world?\", \"table_name\": \"temp1\"},\n",
    "                          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T01:26:54.514537Z",
     "start_time": "2024-04-11T01:26:50.632905Z"
    }
   },
   "id": "2864676c0f73d8f2",
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dr_inference_only.execute([\"search_lancedb\"], \n",
    "           inputs={\"query\": \"How Data is changing the world?\", \"table_name\": \"temp1\"},\n",
    "                          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T04:18:47.049954Z",
     "start_time": "2024-04-11T04:18:43.767788Z"
    }
   },
   "id": "cb661621910276ca",
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9dca46791620e5a6",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
